# ğŸ¤– MCP AI Agent with LangGraph

An intelligent AI agent that connects to Model Context Protocol (MCP) servers, dynamically discovers tools, and maintains conversation memory using LangGraph.

---

## ğŸ“‹ Overview

This project implements an AI agent that:
- Connects to MCP servers via STDIO transport
- Dynamically discovers and invokes tools based on user intent
- Maintains full conversation history and context
- Uses LangGraph for robust state management
- Supports weather queries, stock prices, and web search

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          User                             â”‚
â”‚              (Natural Language Queries)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LangGraph AI Agent                       â”‚
â”‚                       (agent.py)                          â”‚
â”‚                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                  Agent Node (LLM)                 â”‚   â”‚
â”‚   â”‚                                                   â”‚   â”‚
â”‚   â”‚ â€¢ Interprets user intent                          â”‚   â”‚
â”‚   â”‚ â€¢ Uses full conversation history                  â”‚   â”‚
â”‚   â”‚ â€¢ Decides whether a tool call is required         â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                 Tool Node (Executors)             â”‚   â”‚
â”‚   â”‚                                                   â”‚   â”‚
â”‚   â”‚ â€¢ Executes selected tools                         â”‚   â”‚
â”‚   â”‚ â€¢ Handles tool inputs and outputs                 â”‚   â”‚
â”‚   â”‚ â€¢ Returns results back to the agent               â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Client (STDIO)                     â”‚
â”‚                                                           â”‚
â”‚ â€¢ Spawns MCP server as a subprocess                       â”‚
â”‚ â€¢ Discovers available tools dynamically                   â”‚
â”‚ â€¢ Sends and receives MCP protocol messages                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MCP Server                           â”‚
â”‚                    (server/main.py)                       â”‚
â”‚                                                           â”‚
â”‚ â€¢ get_weather                                             â”‚
â”‚ â€¢ get_stock_price                                         â”‚
â”‚ â€¢ web_search                                              â”‚
â”‚                                                           â”‚
â”‚ Exposes tools via MCP with JSON schemas                   â”‚
â”‚ Contains no agent or decision logic                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## ğŸš€ Quick Start

### **Prerequisites**

- Python 3.9+
- Groq API key
- MCP server (included in `server/main.py`)

### **Installation**

1. **Clone the repository**
   ```bash
   cd task2-mcp+agent
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   
   Create a `.env` file in the root directory:
   ```env
   GROQ_API_KEY=your_groq_api_key_here
   ```

4. **Run the agent**
   ```bash
   python agent/agent.py
   ```

---

## ğŸ“¦ Dependencies

```txt
langchain-groq>=0.2.0
langchain>=0.3.0
langgraph>=0.2.0
python-dotenv>=1.0.0
mcp>=1.0.0
pydantic>=2.0.0
```

Install all at once:
```bash
pip install langchain-groq langchain langgraph python-dotenv mcp pydantic
```

---

## ğŸ¯ Usage Examples

### **Basic Queries**

```
You: What is the weather in Paris?
Agent: The current weather in Paris is a clear sky with a temperature 
of 3.87Â°C, humidity of 73%, and wind speed of 4.12 m/s.

You: What is the stock price of TSLA?
Agent: The current stock price of TSLA is $485.4.

You: Search the web for latest AI news
Agent: Based on the search results, here are the latest AI news:
* Google has announced its first AI hub in India...
```

### **Context-Aware Conversations**

```
You: What is the weather in London?
Agent: The current weather in London is 6.04Â°C...

You: What about Tokyo?
Agent: The current weather in Tokyo is 2.97Â°C...

You: What about the previous city?
Agent: London.
```

### **Memory Recall**

```
You: What questions have I asked you?
Agent: You have asked me the following questions:
1. What is the weather in Paris?
2. What about bangalore?
3. What is the stock price of TSLA?
...
```

---

## ğŸ”§ Technical Details

### **Component Breakdown**

#### **1. MCPClient Class**
- Manages STDIO connection to MCP server
- Spawns server process as subprocess
- Handles bidirectional communication
- Discovers available tools via MCP protocol

#### **2. Tool Conversion**
- Converts MCP tool schemas to LangChain StructuredTools
- Maps JSON schema types to Python types (stringâ†’str, integerâ†’int)
- Creates Pydantic models for input validation
- Wraps tool execution in async functions

#### **3. LangGraph Agent**
- **StateGraph**: Manages conversation flow
- **Agent Node**: LLM decision-making with full conversation history
- **Tool Node**: Executes tool calls in parallel
- **Conditional Routing**: Decides whether to use tools or respond

#### **4. Memory System**
- Maintains full conversation history as message list
- Passes complete context to LLM on every turn
- Supports contextual understanding and recall
- No external database required (in-memory)

### **Message Flow**

```
User Input
    â†“
[Add to conversation_history]
    â†“
[Invoke LangGraph agent with full history]
    â†“
Agent Node: LLM analyzes history + new question
    â†“
    â”œâ”€â†’ Needs tool? â†’ Tool Node â†’ Execute â†’ Back to Agent
    â””â”€â†’ Can answer? â†’ Generate response â†’ Return
    â†“
[Add response to conversation_history]
    â†“
Display to User
```

---

## ğŸ› ï¸ Customization

### **Adding New Tools**

1. Add tool to your MCP server (`server/main.py`)
2. Agent will automatically discover it on startup
3. No changes needed to agent code!

### **Changing LLM Model**

```python
llm = ChatGroq(
    groq_api_key=GROQ_API_KEY,
    model_name="llama-3.1-70b-versatile",  # Change model
    temperature=0
)
```

### **Adjusting System Prompt**

Edit the `system_message` in `run_agent()` function:
```python
system_message = SystemMessage(content="""
Your custom instructions here...
""")
```

---

## ğŸ§ª Testing

### **Test Suite**

Run these prompts to verify functionality:

**Tool Invocation:**
```
What is the weather in Paris?
What is the stock price of AAPL?
Search the web for Python 3.12 features
```

**Memory & Context:**
```
What is the weather in London?
What about Tokyo?
What was the temperature in the previous city?
```

**Memory Recall:**
```
What questions have I asked?
What did we discuss earlier?
```

**Direct Answers:**
```
What is 5 + 7?
Tell me a joke
```

### **Expected Behavior**

- âœ… All tools execute successfully
- âœ… Agent maintains context across turns
- âœ… Can recall previous conversation
- âœ… Answers simple questions without tools
- âœ… No infinite loops or errors

---

## ğŸ› Troubleshooting

### **Issue: "GROQ_API_KEY not found"**
**Solution:** Create `.env` file with your API key

### **Issue: "MCP session is not initialized"**
**Solution:** Ensure `server/main.py` exists and is executable

### **Issue: Tool schema validation errors**
**Solution:** Check that MCP server returns correct JSON schema types

### **Issue: Agent doesn't remember previous messages**
**Solution:** Verify `conversation_history` is being appended correctly

---

## ğŸ“š Key Concepts

### **MCP (Model Context Protocol)**
- Standard protocol for connecting AI models to external tools
- Uses JSON-RPC over STDIO/HTTP for communication
- Servers expose tools with JSON schemas

### **LangGraph**
- Framework for building stateful, multi-step AI applications
- Uses directed graphs to control agent behavior
- Prevents common issues like infinite loops

### **ReAct Pattern**
- Reason + Act: LLM thinks, then uses tools, then responds
- LangGraph implements this with function calling (not text parsing)

### **Conversation Memory**
- Full history stored as list of messages
- Each turn: System + History + New Question
- Enables context understanding and recall

---

## ğŸ“– References

- [LangGraph Documentation](https://docs.langchain.com/oss/python/langgraph/overview)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [LangChain Tools](https://python.langchain.com/docs/modules/tools/)

---

## ğŸ“„ License

This project is provided for educational purposes.

---

## ğŸ‘¤ Author

Built as part of MCP integration learning project.

---

## ğŸ™ Acknowledgments

- Anthropic for MCP specification
- LangChain team for LangGraph framework
- Groq for LLM API access
